## Запуск системы

Запуск всех необходимых элементов системы производится командой:

> docker compose up -d --build

Данная команда запустит контейнеры с S3 хранилищем Minio, базой данных Postgres и пайплайном Nifi с registry и zookeeper для сохранения собранных пайплайнов.

После запуска всех контейнеров может потребоваться 5-10 минут, пока nifi полностью загрузится. 

Nifi будет доступен по адресу localhost:8091/nifi
Консоль S3 хранилища будет доступна по адресу localhost:9001. Данные для входа в консоль можно найти в файле .env


## S3 хранилище

В хранилище уже создан bucket testbucket и загружен файл test.csv для воспроизведения результата. Вы можете загрузить свой файл, в таком случае необходимо будет изменить Object Key в процессоре FetchS3Object в Nifi

## Pipeline 

На момент запуска системы все необходимые процессоры в Nifi уже запущены. Если вы загрузили тестовый csv файл с названием, отличным от test.csv, необходимо изменить Object Key в процессоре FetchS3Object, предварительно остановив его. После внесения изменений процессор необходимо запустить вновь. 

Для запуска пайплайна необходимо вызвать команду Run once процессора GenerateFlowFile

По завершении работы пайплайна в таблице public.test базы данных появятся данные из csv файла.

## DDL-команды для создания таблиц в PostgreSQL

Команды для создания таблиц содержатся в файле initial_tables.sql

## Заполнение таблиц тестовыми данными

Для заполнения таблиц тестовыми данными в базе создана хранимая процедура fill_tables(n_rows integer)

Данная процедура забирает n_rows записей из таблицы test, и записывает их в таблицы c, m,t , после чего, удаляет n_rows записей из таблицы test

Пример вызова процедуры для переноса 3000 записей 

> CALL fill_tables(3000)

Скрипт создания процедуры можно найти в файле initial_tables.sql

## Получение агрегатных значений

Для получения агрегатных значений создана хранимая процедура: 

get_aggregates(tablename varchar(50), agg_column agg_column, date_start varchar(20), date_end varchar(20), age_start integer, age_end integer, gender gen, start_sum integer, end_sum integer, mcc_id integer)

Все параметры данной процедуры являются опциональными:

> tablename - название таблицы, в которую будет записан результат\n
> agg_column - колонка, по которой будет проводится агрегация. Возможные значения -
> ('gender', 'mcc_id', 'age', 'month', 'year','amount') по умолчанию агрегация 
> ведётся по полу 'gender'
> date_start, date_end - начальная и конечная дата транзакции
> age_start, age_end - начальный и конечный возраст для группировки
> start_sum, end_sum - начальная и конечная сумма для группировки
> gender - пол
> mcc_id - отрасль

Пример вызова процедуры для получения агрегированных значений по возрасту за 2022 год с суммами транзакций от 1000 до 3000, с записью в таблицу aggr_age_2022_1000_3000:

> call get_aggregates(tablename => 'aggr_age_2022_1000_3000', agg_column => 'age', 
> date_start => '2022-01-01', date_end => '2022-12-21', start_sum => 1000, end_sum =>3000)

## Генерация файла с тестовыми данными

В файле .env необходимо задать переменные окружения: 

> N_CLIENTS - количество клиентов
> N_TRANSACTIONS - количество транзакций
> N_MERCHANTS - количество торговых точек
> FILENAME - название итогового файла

После этого необходимо запустить скрипт генерации файла коммандой:

> source generate_test_csv.sh

В результате работы скрипта в директории проекта появится файл с $FILENAME, который можно будет использовать в работе пайплайна.